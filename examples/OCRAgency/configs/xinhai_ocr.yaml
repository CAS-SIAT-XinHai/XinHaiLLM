controller:
  controller_address: http://localhost:5000

workers:
  - worker_type: mllm
    worker_name: internvl_chat
    worker_address: http://localhost:40001
    worker_host: 0.0.0.0
    worker_port: 40001
    no_register: false
    limit_model_concurrency: 5
    device: cuda
    api_key: EMPTY
  - worker_type: llm
    worker_name: Qwen1.5-7B-Chat
    worker_address: http://localhost:40002
    worker_host: 0.0.0.0
    worker_port: 40002
    no_register: false
    limit_model_concurrency: 5
    device: cuda
    api_key: EMPTY
  - worker_type: OCRTools
    worker_name: paddleocr
    worker_address: http://localhost:40004
    worker_host: 0.0.0.0
    worker_port: 40004
    no_register: false
    limit_model_concurrency: 5
    device: cuda
    api_key: EMPTY
  - worker_type: storage
  - worker_type: Agency
    worker_name: paddleocr
    worker_address: http://localhost:40004
    worker_host: 0.0.0.0
    worker_port: 40004
    no_register: false
    limit_model_concurrency: 5
    device: cuda
    api_key: EMPTY

arena:
  allowed_routing_types: &allowed_routing_types
    - "[Unicast]"

  prompts:
    routing_prompt: 123
    answer_template: &answer_template |-
      {"question answer":""}
    Verify_prompt: &Verify_prompt |-
      You are a {role_description}。
      The user has a question related to image information extraction, and the responses have been provided by both the mllm_agent and the ocr_agent.
      The information provided is as follows:
      （1）User's text question:
          {user_question}
      （2）The required output format and specified fields for the extracted image information:
          {answer_template}
      （3）Response from ocr_agent:
          {ocr_agent_answer}
      （4）Response from mllm_agent:
          {mllm_agent_answer}
      （5）Your task:
          Please determine whether the semantic content of the ocr_agent's and mllm_agent's responses is the same.If:
          1. The responses from both agents are largely similar, output an answer that fully complies with the image information extraction format requirements.
          2. The responses from the two agents differ significantly, choose the answer you believe is the most correct and most relevant to the user's question, and output an answer that fully complies with the image information extraction format requirements.

    mllm_prompt: &mllm_prompt |-
      Now, you are a {role_description}. The known information is as follows:
      (1) User's question:
          {user_question}
      (2) Response template:
          {answer_template}
      Please respond to the user's question according to the provided response template.

    Answer_Refactoring_Template: &Answer_Refactoring_Template |-
      You are a {role_description}. Based on a VQA (Visual Question Answering) task involving an image, the known information includes:
      (1) User's text question:
          {user_question}
      (2) Required output format and specified fields for the extracted image information:
          {answer_template}
      (3) ocr_tool_answer (responsible for recognizing all text in the image):
          '''{ocr_tool_answer}'''
      Now, you need to organize the above information, extract relevant details from the ocr_tool_answer to answer the user's question, and ensure that the response format complies with the required output format for image information extraction.



  name: XinHai OCR

  environment:
    environment_type: ocragency
    environment_id: xinhai_ocr_simulation_4
    controller_address: http://localhost:5000
    topology:
      edges:
        - 0->1
        - 0->2
        - 1->0
        - 2->0
    max_turns: 5

  agents:
    - agent_type: verify_agent
      agent_id: 0
      name: verify_agent
      role_description: verify_agent, based on the user's questions and needs, compare the following agent's answers to see if they are correct and verify the format.
      Verify_prompt_template: *Verify_prompt
      locale: zh
      allowed_routing_types: *allowed_routing_types
      answer_template: *answer_template
      llm: Qwen1.5-7B-Chat
      api_key: EMPTY
      api_base: http://localhost:40002/v1

    - agent_type: mllm_agent
      agent_id: 1
      name: mllm_agent
      role_description: mllm_agent, need to answer user questions based on pictures and the answer template must meet the requirements.
      mllm_prompt_template: *mllm_prompt
      locale: zh
      allowed_routing_types: *allowed_routing_types
      answer_template: *answer_template
      llm: internvl_chat
      api_key: EMPTY
      api_base: http://localhost:40001/v1

    - agent_type: ocr_agent
      agent_id: 2
      name: ocr_agent
      role_description: ocr_agent, question answering assistant.
      Answer_Refactoring_Template: *Answer_Refactoring_Template
      locale: zh
      allowed_routing_types: *allowed_routing_types
      answer_template: *answer_template
      llm: Qwen1.5-7B-Chat
      api_key: EMPTY
      api_base: http://localhost:40002/v1


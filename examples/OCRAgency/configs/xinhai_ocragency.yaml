arena:
  allowed_routing_types: &allowed_routing_types
    - "[Unicast]"

  prompts:
    answer_template: &answer_template |-
      {"question answer":""}
    routing_prompt: &routing_prompt |-
      ## Now, you are playing the role of {agent_name} in the virtual world. You need to react based on your own association with other roles. At present, the known information is as follows:
      
      ### Your role description as {agent_name}:
      {role_description}
      
      ### Summary of historical conversations between you as {agent_name} and other roles:
      {chat_summary}
      
      ### Your latest conversation history with other roles as {agent_name}:
      {chat_history}
      
      ### List of roles that you, as {agent_name}, can interact with:
      {agent_descriptions}
      
      ### The communication methods you can use as {agent_name} are:
      {routing_descriptions}
      
      ## Based on the current situation, please choose a suitable communication target and communication method. If you don't know how to handle the output, please refer to the following output format and output your routing strategy:
      {{"method": "[Multicast]", "target": [2,3,4,5,6]}}
      {{"method": "[Unicast]", "target": [0]}}
      
      ##Attention##
      Now, based on the above information and reference output format, what is your routing strategy?
    Verify_prompt: &Verify_prompt |-
      You are a {role_description}。
      The user has a question related to image information extraction, and the responses have been provided by both the mllm_agent and the ocr_agent.
      The information provided is as follows:
      （1）User's text question:
          {user_question}
      （2）The required output format and specified fields for the extracted image information:
          {answer_template}
      （3）Response from ocr_agent:
          {ocr_agent_answer}
      （4）Response from mllm_agent:
          {mllm_agent_answer}
      （5）Your task:
          Please determine whether the semantic content of the ocr_agent's and mllm_agent's responses is the same.If:
          1. The responses from both agents are largely similar, output an answer that fully complies with the image information extraction format requirements.
          2. The responses from the two agents differ significantly, choose the answer you believe is the most correct and most relevant to the user's question, and output an answer that fully complies with the image information extraction format requirements.

    mllm_prompt: &mllm_prompt |-
      Now, you are a {role_description}. The known information is as follows:
      (1) User's question:
          {user_question}
      (2) Response template:
          {answer_template}
      Please respond to the user's question according to the provided response template.

    Answer_Refactoring_Template: &Answer_Refactoring_Template |-
      You are a {role_description}. Based on a VQA (Visual Question Answering) task involving an image, the known information includes:
      (1) User's text question:
          {user_question}
      (2) Required output format and specified fields for the extracted image information:
          {answer_template}
      (3) ocr_tool_answer (responsible for recognizing all text in the image):
          '''{ocr_tool_answer}'''
      Now, you need to organize the above information, extract relevant details from the ocr_tool_answer to answer the user's question, and ensure that the response format complies with the required output format for image information extraction.

  name: XinHai OCR

  environment:
    environment_type: ocragency
    environment_id: xinhai_ocr_simulation_4
    controller_address: http://controller:5000
    topologies:
      - type: ocragency
        name: OCRAgency
        start: 0
        max_turns: 10
        edges:
          - 0->1
          - 1->0
          - 1->2
          - 1->3
          - 2->1
          - 2->3
          - 3->1
          - 3->2
  agents:
    - agent_type: proxy
      agent_id: 0
      name: user
      role_description: 咨询者，面临心理问题
      routing_prompt_template: *routing_prompt
      summary_prompt_template: *summary_prompt
      prompt_template: *consultant_prompt
      locale: zh
      allowed_routing_types: *allowed_routing_types
      llm: Qwen1.5-7B-Chat
    - agent_type: simple
      agent_id: 0
      name: judge
      role_description: verify_agent, based on the user's questions and needs, compare the following agent's answers to see if they are correct and verify the format.
      routing_prompt_template: *routing_prompt
      Verify_prompt_template: *Verify_prompt
      locale: en
      allowed_routing_types: *allowed_routing_types
      answer_template: *answer_template
      llm: Qwen1.5-7B-Chat
    - agent_type: mllm
      agent_id: 1
      name: mllm
      role_description: mllm_agent, need to answer user questions based on pictures and the answer template must meet the requirements.
      mllm_prompt_template: *mllm_prompt
      locale: zh
      allowed_routing_types: *allowed_routing_types
      answer_template: *answer_template
      llm: Qwen1.5-7B-Chat
      mllm: internvl_chat
    - agent_type: ocr
      agent_id: 2
      name: ocr
      role_description: ocr_agent, question answering assistant.
      Answer_Refactoring_Template: *Answer_Refactoring_Template
      locale: zh
      allowed_routing_types: *allowed_routing_types
      answer_template: *answer_template
      llm: Qwen1.5-7B-Chat

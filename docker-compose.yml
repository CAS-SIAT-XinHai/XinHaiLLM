version: "2.2"

services:
  controller:
    image: xinhai
    volumes:
      - ./backend:/usr/share/xinhai/backend
      - ./configs:/usr/share/xinhai/configs
      - ./related_repos:/usr/share/xinhai/related_repos
    ports:
      - 8080:8080
      - ${CONTROLLER_PORT}:${CONTROLLER_PORT}
    environment:
      PYTHONPATH: /usr/share/xinhai/related_repos/LLaMA-Factory/src
    command: python -m xinhai.controller --host ${CONTROLLER_HOST} --port ${CONTROLLER_PORT}
    healthcheck:
      test:
        [
          "CMD-SHELL",
          "curl -s http://localhost:5000 | grep 'detail'",
        ]
      interval: 10s
      timeout: 10s
      retries: 120
  frontend:
    image: xinhai
    volumes:
      - ./frontend:/usr/share/xinhai/frontend
      - ./configs:/usr/share/xinhai/configs
    network_mode: service:controller
    working_dir: /usr/share/xinhai/frontend
    command: npm run serve
  storage:
    image: xinhai
    depends_on:
      - controller
    volumes:
      - ./backend:/usr/share/xinhai/backend
      - ./configs:/usr/share/xinhai/configs
      - ./related_repos:/usr/share/xinhai/related_repos
      - pretrained_models:/usr/share/xinhai/pretrained_models
    environment:
      PYTHONPATH: /usr/share/xinhai/related_repos/LLaMA-Factory/src
      CONTROLLER_ADDRESS: http://controller:${CONTROLLER_PORT}
      MODEL_NAME: storage
      WORKER_ADDRESS: http://storage:${STORAGE_WORKER_PORT}
      WORKER_HOST: 0.0.0.0
      WORKER_PORT: ${STORAGE_WORKER_PORT}
      DB_PATH: /usr/share/xinhai/pretrained_models/${STORAGE_DB_PATH}
      EMBEDDING_MODEL_PATH: /usr/share/xinhai/pretrained_models/${STORAGE_EMBEDDING_MODEL_PATH}
    command: python -m xinhai.workers.storage
    deploy:
      resources:
        reservations:
          devices:
            - driver: nvidia
              device_ids: [ '0' ]
              capabilities: [ gpu ]
  llm:
    image: xinhai
    depends_on:
      - controller
      - storage
    volumes:
      - ./backend:/usr/share/xinhai/backend
      - ./configs:/usr/share/xinhai/configs
      - ./related_repos:/usr/share/xinhai/related_repos
      - pretrained_models:/usr/share/xinhai/pretrained_models
    environment:
      PYTHONPATH: /usr/share/xinhai/related_repos/LLaMA-Factory/src
      CONTROLLER_ADDRESS: http://controller:${CONTROLLER_PORT}
      MODEL_NAME: ${LLM_MODEL_NAME}
      WORKER_ADDRESS: http://llm:${LLM_WORKER_PORT}
      WORKER_HOST: 0.0.0.0
      WORKER_PORT: ${LLM_WORKER_PORT}
    command: python -m xinhai.workers.llm --model_name_or_path /usr/share/xinhai/pretrained_models/${LLM_MODEL_PATH} --template ${LLM_MODEL_TEMPLATE} --infer_backend vllm --vllm_enforce_eager --infer_dtype float16
    deploy:
      resources:
        reservations:
          devices:
            - driver: nvidia
              device_ids: [ '0' ]
              capabilities: [ gpu ]
  mllm:
    image: xinhai
    depends_on:
      - controller
      - storage
    volumes:
      - ./backend:/usr/share/xinhai/backend
      - ./configs:/usr/share/xinhai/configs
      - ./related_repos:/usr/share/xinhai/related_repos
      - pretrained_models:/usr/share/xinhai/pretrained_models
    environment:
      PYTHONPATH: /usr/share/xinhai/related_repos/LLaMA-Factory/src
      CONTROLLER_ADDRESS: http://controller:${CONTROLLER_PORT}
      MODEL_NAME: ${MLLM_MODEL_NAME}
      MODEL_PATH: /usr/share/xinhai/pretrained_models/${MLLM_MODEL_PATH}
      WORKER_ADDRESS: http://mllm:${MLLM_WORKER_PORT}
      WORKER_HOST: 0.0.0.0
      WORKER_PORT: ${MLLM_WORKER_PORT}
    command: python -m xinhai.workers.mllm
    deploy:
      resources:
        reservations:
          devices:
            - driver: nvidia
              device_ids: [ '1' ]
              capabilities: [ gpu ]
  bridge:
    image: xinhai
    depends_on:
      - controller
      - storage
    volumes:
      - ./backend:/usr/share/xinhai/backend
      - ./configs:/usr/share/xinhai/configs
      - ./related_repos:/usr/share/xinhai/related_repos
    environment:
      PYTHONPATH: /usr/share/xinhai/related_repos/LLaMA-Factory/src
      CONTROLLER_ADDRESS: http://controller:${CONTROLLER_PORT}
      MODEL_NAME: Qwen/Qwen2-7B-Instruct
      WORKER_ADDRESS: http://bridge:${BRIDGE_WORKER_PORT}
      WORKER_HOST: 0.0.0.0
      WORKER_PORT: ${BRIDGE_WORKER_PORT}
      API_KEY: ${BRIDGE_API_KEY}
      API_BASE: ${BRIDGE_API_BASE}
    command: python -m xinhai.workers.bridge

volumes:
  backend:
    driver: local
  configs:
    driver: local
  related_repos:
    driver: local
  pretrained_models:
    driver: local
    driver_opts:
      o: bind
      type: none
      device: /data/pretrained_models
